{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOV Segmentation # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in d:\\temporay segmentation\\.venv\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: roboflow in d:\\temporay segmentation\\.venv\\lib\\site-packages (1.1.54)\n",
      "Requirement already satisfied: supervision in d:\\temporay segmentation\\.venv\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: opencv-python-headless in d:\\temporay segmentation\\.venv\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy in d:\\temporay segmentation\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: werkzeug in d:\\temporay segmentation\\.venv\\lib\\site-packages (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from flask) (3.1.5)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from flask) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.9 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from flask) (1.9.0)\n",
      "Requirement already satisfied: certifi in d:\\temporay segmentation\\.venv\\lib\\site-packages (from roboflow) (2025.1.31)\n",
      "Requirement already satisfied: idna==3.7 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from roboflow) (3.7)\n",
      "Requirement already satisfied: cycler in d:\\temporay segmentation\\.venv\\lib\\site-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from roboflow) (1.4.8)\n",
      "Requirement already satisfied: matplotlib in d:\\temporay segmentation\\.venv\\lib\\site-packages (from roboflow) (3.10.0)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from roboflow) (11.1.0)\n",
      "Requirement already satisfied: python-dateutil in d:\\temporay segmentation\\.venv\\lib\\site-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv in d:\\temporay segmentation\\.venv\\lib\\site-packages (from roboflow) (1.0.1)\n",
      "Requirement already satisfied: requests in d:\\temporay segmentation\\.venv\\lib\\site-packages (from roboflow) (2.32.3)\n",
      "Requirement already satisfied: six in d:\\temporay segmentation\\.venv\\lib\\site-packages (from roboflow) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from roboflow) (2.3.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from roboflow) (6.0.2)\n",
      "Requirement already satisfied: requests-toolbelt in d:\\temporay segmentation\\.venv\\lib\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: filetype in d:\\temporay segmentation\\.venv\\lib\\site-packages (from roboflow) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.3.0 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from supervision) (1.3.1)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from supervision) (0.7.1)\n",
      "Requirement already satisfied: opencv-python>=4.5.5.64 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from supervision) (4.11.0.86)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from supervision) (1.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from werkzeug) (3.0.2)\n",
      "Requirement already satisfied: colorama in d:\\temporay segmentation\\.venv\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from matplotlib->roboflow) (4.56.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from matplotlib->roboflow) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from matplotlib->roboflow) (3.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from requests->roboflow) (3.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install flask roboflow supervision opencv-python-headless numpy werkzeug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask_cors in d:\\temporay segmentation\\.venv\\lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: Flask>=0.9 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from flask_cors) (3.1.0)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from Flask>=0.9->flask_cors) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from Flask>=0.9->flask_cors) (3.1.5)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from Flask>=0.9->flask_cors) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from Flask>=0.9->flask_cors) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.9 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from Flask>=0.9->flask_cors) (1.9.0)\n",
      "Requirement already satisfied: colorama in d:\\temporay segmentation\\.venv\\lib\\site-packages (from click>=8.1.3->Flask>=0.9->flask_cors) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\temporay segmentation\\.venv\\lib\\site-packages (from Jinja2>=3.1.2->Flask>=0.9->flask_cors) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install flask_cors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Starting Flask server on http://127.0.0.1:5000\n",
      " * Serving Flask app '__main__'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received file: ezgif-frame-014.jpg, saved to ./uploaded_image.jpg\n",
      "Processing image: ./uploaded_image.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Feb/2025 14:55:15] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated image saved: ./annotated_image.jpg\n",
      "Sending processed image response\n",
      "Received file: ezgif-frame-014.jpg, saved to ./uploaded_image.jpg\n",
      "Processing image: ./uploaded_image.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Feb/2025 14:55:46] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated image saved: ./annotated_image.jpg\n",
      "Sending processed image response\n",
      "Received file: ezgif-frame-001.jpg, saved to ./uploaded_image.jpg\n",
      "Processing image: ./uploaded_image.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Feb/2025 15:22:31] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated image saved: ./annotated_image.jpg\n",
      "Sending processed image response\n",
      "Received file: ezgif-frame-013.jpg, saved to ./uploaded_image.jpg\n",
      "Processing image: ./uploaded_image.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Feb/2025 15:25:59] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated image saved: ./annotated_image.jpg\n",
      "Sending processed image response\n",
      "Received file: ezgif-frame-002.jpg, saved to ./uploaded_image.jpg\n",
      "Processing image: ./uploaded_image.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Feb/2025 15:31:10] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated image saved: ./annotated_image.jpg\n",
      "Sending processed image response\n",
      "Received file: ezgif-frame-001.jpg, saved to ./uploaded_image.jpg\n",
      "Processing image: ./uploaded_image.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Feb/2025 15:33:01] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated image saved: ./annotated_image.jpg\n",
      "Sending processed image response\n",
      "Received file: ezgif-frame-001.jpg, saved to ./uploaded_image.jpg\n",
      "Processing image: ./uploaded_image.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Feb/2025 15:36:29] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated image saved: ./annotated_image.jpg\n",
      "Sending processed image response\n",
      "Received file: ezgif-frame-020.jpg, saved to ./uploaded_image.jpg\n",
      "Processing image: ./uploaded_image.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Feb/2025 15:39:03] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated image saved: ./annotated_image.jpg\n",
      "Sending processed image response\n",
      "Received file: Sample testing Image.jpg, saved to ./uploaded_image.jpg\n",
      "Processing image: ./uploaded_image.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Feb/2025 16:04:58] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated image saved: ./annotated_image.jpg\n",
      "Sending processed image response\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, send_file, jsonify\n",
    "from flask_cors import CORS\n",
    "from roboflow import Roboflow\n",
    "import supervision as sv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import threading\n",
    "import nest_asyncio\n",
    "import os\n",
    "\n",
    "# Allow Flask and Jupyter to run together\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # Enable CORS for all requests\n",
    "\n",
    "# Apply CORS headers manually (for safety)\n",
    "@app.after_request\n",
    "def add_cors_headers(response):\n",
    "    response.headers[\"Access-Control-Allow-Origin\"] = \"*\"\n",
    "    response.headers[\"Access-Control-Allow-Methods\"] = \"GET, POST, OPTIONS\"\n",
    "    response.headers[\"Access-Control-Allow-Headers\"] = \"Content-Type, Authorization\"\n",
    "    return response\n",
    "\n",
    "# Initialize Roboflow API\n",
    "RF_API_KEY = \"8Qa7KjefjGCaCBRyRn7D\"\n",
    "rf = Roboflow(api_key=RF_API_KEY)\n",
    "project = rf.workspace().project(\"tissue-v2\")\n",
    "model = project.version(4).model\n",
    "\n",
    "def process_image(image_path):\n",
    "    \"\"\"Process the image using Roboflow and Supervision.\"\"\"\n",
    "    print(f\"Processing image: {image_path}\")\n",
    "\n",
    "    if not os.path.exists(image_path):\n",
    "        print(\"Error: Image file not found!\")\n",
    "        return None\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    try:\n",
    "        results = model.predict(image_path, confidence=40, overlap=30).json()\n",
    "    except Exception as e:\n",
    "        print(\"Error during model prediction:\", e)\n",
    "        return None\n",
    "\n",
    "    # Convert Roboflow results to Supervision Detections format\n",
    "    xyxy, confidences, class_ids = [], [], []\n",
    "    class_name_to_id = {}\n",
    "\n",
    "    for prediction in results.get('predictions', []):\n",
    "        x1 = prediction['x'] - prediction['width'] / 2\n",
    "        y1 = prediction['y'] - prediction['height'] / 2\n",
    "        x2 = prediction['x'] + prediction['width'] / 2\n",
    "        y2 = prediction['y'] + prediction['height'] / 2\n",
    "        xyxy.append([x1, y1, x2, y2])\n",
    "        confidences.append(prediction['confidence'])\n",
    "\n",
    "        class_name = prediction['class']\n",
    "        if class_name not in class_name_to_id:\n",
    "            class_name_to_id[class_name] = len(class_name_to_id)\n",
    "        class_ids.append(class_name_to_id[class_name])\n",
    "\n",
    "    # Convert detections into the required format\n",
    "    detections = sv.Detections(\n",
    "        xyxy=np.array(xyxy, dtype=np.float32),\n",
    "        confidence=np.array(confidences, dtype=np.float32),\n",
    "        class_id=np.array(class_ids, dtype=int)\n",
    "    )\n",
    "\n",
    "    # Annotate the image\n",
    "    bounding_box_annotator = sv.BoxAnnotator()\n",
    "    annotated_image = bounding_box_annotator.annotate(scene=image, detections=detections)\n",
    "\n",
    "    for i, (x1, y1, x2, y2) in enumerate(detections.xyxy.astype(int)):\n",
    "        class_id = detections.class_id[i]\n",
    "        label = list(class_name_to_id.keys())[class_id]\n",
    "        confidence = detections.confidence[i]\n",
    "        cv2.putText(\n",
    "            annotated_image,\n",
    "            f\"{label} {confidence:.2f}\",\n",
    "            (x1, y1 - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 255, 0),\n",
    "            2,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "    # Save the annotated image\n",
    "    output_path = \"./annotated_image.jpg\"\n",
    "    cv2.imwrite(output_path, annotated_image)\n",
    "    print(f\"Annotated image saved: {output_path}\")\n",
    "\n",
    "    return output_path\n",
    "\n",
    "@app.route(\"/process\", methods=[\"POST\"])\n",
    "def process():\n",
    "    \"\"\"API Endpoint to process the uploaded image.\"\"\"\n",
    "    if \"file\" not in request.files:\n",
    "        print(\"Error: No file uploaded\")\n",
    "        return jsonify({\"error\": \"No file uploaded\"}), 400\n",
    "\n",
    "    file = request.files[\"file\"]\n",
    "    image_path = \"./uploaded_image.jpg\"\n",
    "    file.save(image_path)\n",
    "\n",
    "    print(f\"Received file: {file.filename}, saved to {image_path}\")\n",
    "\n",
    "    # Process the image\n",
    "    output_path = process_image(image_path)\n",
    "    if not output_path:\n",
    "        return jsonify({\"error\": \"Failed to process image\"}), 500\n",
    "\n",
    "    print(\"Sending processed image response\")\n",
    "    return send_file(output_path, mimetype='image/jpeg')\n",
    "\n",
    "def run_app():\n",
    "    \"\"\"Function to run Flask app in a separate thread.\"\"\"\n",
    "    print(\"Starting Flask server on http://127.0.0.1:5000\")\n",
    "    app.run(debug=False, use_reloader=False, port=5000)\n",
    "\n",
    "# Start Flask in a background thread so Jupyter Notebook doesn't block\n",
    "thread = threading.Thread(target=run_app, daemon=True)\n",
    "thread.start()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
